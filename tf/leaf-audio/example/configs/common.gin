# -*-Python-*-

import example.external_configurables
import leaf_audio.frontend
import leaf_audio.models
import leaf_audio.pooling
import leaf_audio.postprocessing

# HYPERPARAMETERS
train.workdir = '/tmp/leaf_audio/'
train.dataset = 'speech_commands'
train.num_epochs = 10
train.learning_rate = 1e-4
train.batch_size = 64

# AUDIO PRE-PROCESSING
data.prepare.transform_fns = [@data.align, @data.loudness_normalization]
loudness_normalization.target_db = 15.0
loudness_normalization.max_gain_db = 30.0
align.seq_len = 16000

# PICK YOUR ENCODER
AudioClassifier.encoder = @ConvNet()

# ENCODER PARAMETERS
ConvNet.filters = [64, 128, 256, 256, 512, 512]
ConvBlock.activation = 'relu'
ConvBlock.dropout = 0.1
